## ğŸ› ï¸ Synthron â€“ Custom PC Recommendation Platform

**Synthron** is a full-stack web application that helps users intelligently build custom PC configurations based on their needs (gaming, editing, budget, etc.) using a combination of AI prompt parsing and real-time price scraping from trusted websites.

The system uses **React** for the frontend and **Django + Django REST Framework** on the backend, connected via REST APIs.**PostgreSQL** is used to store User's data and **Redis** acts as a cache system to temporarily store the results for faster accessibility. It uses an **LLM (LLaMA 3.2)** locally to interpret user prompts, and **Playwright** for dynamic scraping of part prices and availability.

> ğŸ” Currently achieving **70â€“75% scraping predictability/accuracy**. Further improvements are planned.


---



## âœ¨ Features

- ğŸ§  **AI-driven prompt interpretation** (LLaMA 3.2)
- ğŸ” **Real-time scraping** of PC parts from trusted e-commerce websites
- âš™ï¸ **Component agents**: CPU, GPU, RAM, Storage, Motherboard
- ğŸŒ **Region-aware pricing** and availability
- ğŸ” **JWT-based authentication** with HttpOnly cookie storage
- ğŸ“¦ **Build history**: Saved per user and fetchable later
- ğŸ§ª **Compatibility checker**: Validates part compatibility (e.g., socket types)
- âš¡ Fast, modern UI using **React + Tailwind CSS**

---

## ğŸ“ Folder Structure

```
ai-pc-builder/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”œâ”€â”€ cpu_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gpu_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ram_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ storage_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ motherboard_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llama.py
â”‚   â”‚   â”‚   â”œâ”€â”€ playwright_scraper.py
â”‚   â”‚   â”‚   â””â”€â”€ product_finder.py
â”‚   â”‚   â”œâ”€â”€ compatibility_checker.py
â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ api.js        
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ index.jsx
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
â””â”€â”€ .env
â””â”€â”€ .docker-compose.yml

```

---

## âš™ï¸ Backend â€“ Django Setup

### 1. Clone and set up virtual environment:

```bash
git clone https://github.com/yourusername/ai-pc-builder.git
cd ai-pc-builder/backend

python -m venv env
source env/bin/activate  # Windows: env\Scripts\activate

pip install -r requirements.txt
```

### 2. Create `.env` file:

```
SECRET_KEY=your_django_secret_key
DEBUG=True
ALLLOWED_HOSTS=localhost,127.0.0.1
DB_NAME=
DB_USER=
DB_PASSWORD=
DB_HOST=
DB_PORT=5432
```

### 3. Run migrations and start server:

```bash
python manage.py makemigrations
python manage.py migrate
python manage.py runserver
```

### ğŸ“¦ Backend Dependencies (`backend/requirements.txt`)

```
Django>=4.2
djangorestframework
python-dotenv
httpx
playwright
psycopg2-binary
```

To install Playwright browsers:

```bash
playwright install
```

---

## ğŸ¨ Frontend â€“ React Setup

### 1. Navigate to frontend directory:

```bash
cd ../frontend
```

### 2. Install dependencies:

```bash
npm install
```

### 3. Run development server:

```bash
npm run start
```
## ğŸ³ Docker Setup (Recommended)

Synthron is fully containerized. This is the fastest way to get the project running.

### 1. Environment Variables (`.env`)
Create a `.env` file in the project root:

```env
COMPOSE_PROJECT_NAME=synthron

# PostgreSQL
POSTGRES_DB=synthron
POSTGRES_USER=synthron
POSTGRES_PASSWORD=synthronpassword

# Django Backend
DJANGO_SETTINGS_MODULE=config.settings.production
DJANGO_SECRET_KEY=your-secret-key-here
DEBUG=false
ALLOWED_HOSTS=*

DATABASE_URL=postgres://synthron:synthronpassword@postgres:5432/synthron
REDIS_URL=redis://redis:6379/0
OLLAMA_BASE_URL=http://ollama:11434

# Frontend
VITE_API_BASE_URL=http://localhost:8000
```
---
## âš“ Docker-Compose File
   Make a docker-compose.yml file in your project directory and attach the code below.

   ``` dockercompose
version: "3.9"

services:
  postgres:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks: [synthron-net]

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    networks: [synthron-net]

  ollama:
    image: ollama/ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks: [synthron-net]

  backend:
    build: ./backend
    restart: unless-stopped
    env_file: [.env]
    depends_on:
      - postgres
      - redis
      - ollama
    ports:
      - "8000:8000"
    networks: [synthron-net]

  frontend:
    build: ./frontend
    restart: unless-stopped
    env_file: [.env]
    depends_on:
      - backend
    ports:
      - "3000:80"
    networks: [synthron-net]

volumes:
  postgres_data:
  ollama_data:

networks:
  synthron-net:
    driver: bridge
   ```
---


## âš ï¸ LLaMA 3.2 Usage

Synthron uses **LLaMA 3.2 locally** for AI prompt parsing.  
   - **Docker Users**: Handled automatically via the ollama service.  
      
   - **Manual Users**: Install Ollama and run ollama pull llama3.2.

---


## ğŸ”— How It Works

1. **User Input**: "I want a gaming PC under $1000 in Usa and i prefer an AMD build."
2. **LLM** parses intent, budget, and region.
3. Each **component agent** (CPU, GPU, RAM, etc.) activates.
4. Agents create **product-specific search queries**.
5. **Serper** fetches urls off the web.
6. **Playwright** scrapes trusted e-commerce websites.
7. Components are selected and ranked by:
   - ğŸ”„ Stock availability
   - ğŸ’° Lowest price
   - ğŸ™‹ User preference
8. The **result** is rendered on the frontend with prices and product links.

---

## âœ… Trusted Sites Scraped

- [Amazon](https://amazon.com)
- [Newegg](https://newegg.com)
- [Microcenter](https://microcenter.com)
- [Scan UK](https://scan.co.uk)
- And moreâ€¦

> ğŸ—‘ï¸ `ScrapeGraph` API was removed due to limited free-tier usage. All scraping is now handled with Playwright.

---

## âš ï¸ Known Limitations

- ğŸ›’ Scraping accuracy is 70â€“75% â€” dynamic rendering and anti-bot measures may impact results.
- âŒ Not all product queries yield valid results (fallback logic is used).
- ğŸŒ Currency and regional detection are still basic.

---

## ğŸ”® Roadmap

- ğŸ§  Improve scraping reliability via AI heuristics
- ğŸ”Œ Add PSU and case suggestions
- ğŸ’¸ Integrate Amazon Affiliate tracking
- ğŸ“Š Admin dashboard for scraping diagnostics
- ğŸ” OAuth login support (Google, GitHub)
- ğŸ› ï¸ Improving LLM integration and scraping engine.

---


## ğŸ§  What's Next?

Iâ€™ll be actively improving Synthron with:

- âœ¨ More exciting features and enhancements
- ğŸ› ï¸ Integration of modern **DevOps tooling and workflows**
- âš™ï¸ Implementation of **CI/CD pipelines**
- ğŸš€ **Cloud deployment** on **AWS**


---

## ğŸ¤ Want to Contribute?
Contact me on my email:
rehansaqib2006@gmail.com

**Feel free to open an issue or PR!**