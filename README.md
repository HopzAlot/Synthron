# ğŸ› ï¸ Synthron â€“ Custom PC Recommendation Platform

**Synthron** is a full-stack web application that helps users intelligently build custom PC configurations based on their needs (gaming, editing, budget, etc.) using a combination of AI prompt parsing and real-time price scraping from trusted websites.

The system uses **React** for the frontend and **Django + Django REST Framework** on the backend, connected via REST APIs. It uses an **LLM (TinyLLaMA or LLaMA 3.2)** to interpret user prompts, and **Playwright** for dynamic scraping of part prices and availability.

> ğŸ” Currently achieving **70â€“75% scraping predictability/accuracy**. Further improvements are planned.

---

## âœ¨ Features

- ğŸ§  **AI-driven prompt interpretation** (LLaMA 3.2)
- ğŸ” **Real-time scraping** of PC parts from trusted e-commerce websites
- âš™ï¸ **Component agents**: CPU, GPU, RAM, Storage, Motherboard
- ğŸŒ **Region-aware pricing** and availability
- ğŸ” **JWT-based authentication** with HttpOnly cookie storage
- ğŸ“¦ **Build history**: Saved per user and fetchable later
- ğŸ§ª **Compatibility checker**: Validates part compatibility (e.g., socket types)
- âš¡ Fast, modern UI using **React + Tailwind CSS**

---

## ğŸ“ Folder Structure

```
ai-pc-builder/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”œâ”€â”€ cpu_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gpu_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ram_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ storage_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ motherboard_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llama.py
â”‚   â”‚   â”‚   â”œâ”€â”€ playwright_scraper.py
â”‚   â”‚   â”‚   â””â”€â”€ product_finder.py
â”‚   â”‚   â”œâ”€â”€ compatibility_checker.py
â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ api.js        
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ index.jsx
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Backend â€“ Django Setup

### 1. Clone and set up virtual environment:

```bash
git clone https://github.com/yourusername/ai-pc-builder.git
cd ai-pc-builder/backend

python -m venv env
source env/bin/activate  # Windows: env\Scripts\activate

pip install -r requirements.txt
```

### 2. Create `.env` file:

```
SECRET_KEY=your_django_secret_key
DEBUG=True
DATABASE_URL=postgres://username:password@localhost:5432/pcbuilder
```

### 3. Run migrations and start server:

```bash
python manage.py makemigrations
python manage.py migrate
python manage.py runserver
```

### ğŸ“¦ Backend Dependencies (`backend/requirements.txt`)

```
Django>=4.2
djangorestframework
python-dotenv
httpx
playwright
psycopg2-binary
```

To install Playwright browsers:

```bash
playwright install
```

---

## ğŸ¨ Frontend â€“ React Setup

### 1. Navigate to frontend directory:

```bash
cd ../frontend
```

### 2. Install dependencies:

```bash
npm install
```

### 3. Run development server:

```bash
npm run start
```

---

## ğŸ”— How It Works

1. **User Input**: "I want a gaming PC under $1000 in Usa and i prefer an AMD build."
2. **LLM** parses intent, budget, and region.
3. Each **component agent** (CPU, GPU, RAM, etc.) activates.
4. Agents create **product-specific search queries**.
5. **Serper** fetches urls off the web.
6. **Playwright** scrapes trusted e-commerce websites.
7. Components are selected and ranked by:
   - ğŸ”„ Stock availability
   - ğŸ’° Lowest price
   - ğŸ™‹ User preference
8. The **result** is rendered on the frontend with prices and product links.

---

## âœ… Trusted Sites Scraped

- [Amazon](https://amazon.com)
- [Newegg](https://newegg.com)
- [Microcenter](https://microcenter.com)
- [Scan UK](https://scan.co.uk)
- And moreâ€¦

> ğŸ—‘ï¸ `ScrapeGraph` API was removed due to limited free-tier usage. All scraping is now handled with Playwright.

---

## âš ï¸ Known Limitations

- ğŸ›’ Scraping accuracy is 70â€“75% â€” dynamic rendering and anti-bot measures may impact results.
- âŒ Not all product queries yield valid results (fallback logic is used).
- ğŸŒ Currency and regional detection are still basic.

---

## ğŸ”® Roadmap

- ğŸ§  Improve scraping reliability via AI heuristics
- ğŸ”Œ Add PSU and case suggestions
- ğŸ’¸ Integrate Amazon Affiliate tracking
- ğŸ“Š Admin dashboard for scraping diagnostics
- ğŸ” OAuth login support (Google, GitHub)

---

ğŸ› ï¸ Currently improving LLM integration and scraping engine.

---


---

## ğŸ¤ Want to Contribute?
Contact me on my email:
rehansaqib2006@gmail.com

Feel free to open an issue or PR!
